# -*- coding: utf-8 -*-
"""DeepFake.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KeUTFPKRDdke9LMcbGrg3xVhUR5vaMS5

first i have used resnet50 pretrained model with diffrent epoch values and batch size , result are as follows
1. batch size = 64 and epoch = 10
accuraccy was around 67 percent at the end
2. batch size = 32 and epoch = 50
accuraccy was 61.12% percent .
"""

from google.colab import drive
drive.mount('/content/drive')

from shutil import copy

copy("/content/drive/MyDrive/Colab Notebooks/deepfake dataset/archive (2).zip", "/content/data.zip")

! unzip data.zip

!pip install tensorflow opencv-python numpy matplotlib

"""image generation and preprossesing"""

!nvidia-smi

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define data augmentation and preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,

)

# Load and preprocess data
train_generator = datagen.flow_from_directory(
    'Dataset/Train',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary',
)

validation_generator = datagen.flow_from_directory(
    'Dataset/Validation',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary',
)

test_generator = datagen.flow_from_directory(
    'Dataset/Test',
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
)

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model


# Load pre-trained ResNet50
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))

# Add custom classification head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Freeze pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""**So are you  thinking now , why ADAM as optimiser and Binary cross entropy as a loss measurement function ?**

The reason is as follows , Adam uses individual adaptive learning rates for each parameter, which helps it navigate the complex loss landscape of deepfake detection tasks. Deepfake detection models often need to learn subtle differences between real and manipulated faces or audio, and Adam's adaptability allows it to adjust learning rates for individual features, optimizing for both prominent and nuanced details.It also  combines momentum with bias correction, allowing it to converge faster and avoid getting stuck in local minima. Deepfake detection models typically have a large number of parameters, and efficient convergence is crucial for training them effectively. Adam's momentum term helps it build on previous updates, while the bias correction term prevents it from being misled by initial noise or inaccurate gradients.


moreover, binary cross entropy is a suitable loss function for deepfake detection as it is used  for tasks like binary classification.in other words  it tells the model how far its predictions are from the actual truth (real or fake) and helps it adjust its course to get better at predicting  them apart.BCE calculates the difference between the model's prediction and the actual truth. Let's say the model predicts a image is 80% likely to be real (0.8), but it's actually fake. BCE will calculate the error between 0.8 and 0 (the actual truth).


"""

history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator) //32 ,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=len(validation_generator)
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test loss: {loss:.4f}")
print(f"Test accuracy: {accuracy * 100:.2f}%")

!pip install gradio

import gradio as gr

import gradio as gr
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model

# Load the pretrained ResNet50 model
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))

# Add custom classification head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)

# Define the complete model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the pretrained layers
for layer in base_model.layers:
    layer.trainable = False

def predict_image(image):

    image =tf.image.resize(
    image,
    size = (256,256)

)
    image = tf.expand_dims(image, axis=0)
    prediction = model.predict(image)
    label = "Real" if prediction[0][0] < 0.5 else "Fake"
    return label

# Create the Gradio interface
iface = gr.Interface(
    predict_image,
    [gr.Image( label="Yha image upload karde bhai")],
    "textbox",
    live=True,
)

# Launch the interface
iface.launch(debug = True)

import matplotlib.pyplot as plt

# Data for the bar graph
train_acc_relu = [0.6162, 0.6774, 0.674]
train_acc_elu = [0.493, 0.506, 0.498]
epochs = range(1, len(train_acc_relu) + 1)

# Width of each bar
bar_width = 0.35

# Create separate bars for ReLU and ELU with offset
plt.bar(epochs, train_acc_relu, width=bar_width, label='ReLU Accuracy')
plt.bar([x + bar_width for x in epochs], train_acc_elu, width=bar_width, label='ELU Accuracy')

# Customize the graph
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('ResNet Accuracy for Deepfake Detection with Different Activation Functions')
plt.legend()
plt.xticks(epochs)  # Display epoch numbers on x-axis
plt.xlim(min(epochs) - bar_width, max(epochs) + bar_width)  # Adjust x-axis limits

# Display the graph
plt.tight_layout()  # Adjust layout for better spacing
plt.show()

import matplotlib.pyplot as plt

# Assumed values for training and validation accuracy
train_acc = [ 0.6162 , 0.7052 ,0.6659, 0.6882, 0.6774,  0.674]
val_acc = [ 0.6533,0.6717, 0.6701,0.6408,0.672, 0.627]

epochs = range(1, len(train_acc) + 1)

plt.plot(epochs, train_acc, label='Training Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('ResNet Accuracy for Deepfake Detection')
plt.legend()
plt.show()



"""#possible reasons behind good accuracy of relu over elu in deep fake detection

**1. Non-linearity:**

- ReLU introduces non-linearity into the activation function, allowing the model to learn complex relationships between features in the data. This is **crucial for deepfake detection, as subtle differences in facial expressions, textures, and lighting **can distinguish real and fake images.
- ELU, while also non-linear, has a smoother "ramp-up" than ReLU, potentially making it less sensitive to these subtle variations.

**2. Sparsity:**

- ReLU introduces sparsity in the network, meaning many neurons become inactive during calculations. This can lead to improved computational efficiency and potentially help prevent overfitting, especially in smaller datasets like deepfake detection training sets.
- ELU generally leads to less sparsity, with more neurons remaining active. While this can capture more information, it might also increase the risk of overfitting on limited data.

**3. Gradient Flow:**

- ReLU has a constant gradient for positive values, allowing for easier flow of information back through the network during training. This can be beneficial for tasks like deepfake detection where precise pixel-level feature differentiation is important.
- ELU's gradient is continuously decreasing, potentially making it harder for the network to learn subtle feature-level differences in deepfakes.

**Examples:**

- Imagine a deepfake with slightly blurred skin texture. ReLU's sensitivity to such changes might allow the model to learn specific features related to blurriness and classify it correctly. ELU, due to its smoother activation, might not capture this subtle difference as effectively.
- Another example could be minute inconsistencies in lighting around the eyes in a deepfake. ReLU's ability to differentiate these lighting variations based on pixel-level changes might provide better accuracy compared to ELU's potentially smoother response.



"""

train_acc_Resnet = [0.6162, 0.6774, 0.674,0.6533,0.6278]
train_acc_mobileNET = [0.564, 0.546, 0.598,0.57,0.585]
epochs = range(1, len(train_acc_relu) + 1)

# Width of each bar
bar_width = 0.35

# Create separate bars for ReLU and ELU with offset
plt.bar(epochs, train_acc_relu, width=bar_width, label='train_acc_Resnet')
plt.bar([x + bar_width for x in epochs], train_acc_elu, width=bar_width, label='train_acc_mobileNET')

# Customize the graph
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('ResNet Accuracy for Deepfake Detection with Different Activation Functions')
plt.legend()
plt.xticks(epochs)  # Display epoch numbers on x-axis
plt.xlim(min(epochs) - bar_width, max(epochs) + bar_width)  # Adjust x-axis limits

# Display the graph
plt.tight_layout()  # Adjust layout for better spacing
plt.show()

"""possible reasons behind better accuracy of resnet over mobilenet
**1. Model Complexity and Depth:**

* **ResNet:** Utilizes residual connections that skip layers, allowing for deeper networks without degradation issues. Deeper networks can extract more complex features and capture subtle nuances in deepfakes.
* **MobileNet:** Employs depthwise separable convolutions and inverted residual blocks to achieve efficiency, but this often leads to shallower architectures. Shallower models might struggle with the intricate manipulations involved in deepfakes.

**Image showing ResNet vs MobileNet architecture:**



**2. Feature Extraction Capability:**

* **ResNet:** Residual connections enable information flow across deeper layers, preserving low-level details crucial for identifying deepfake artifacts like blurring or unnatural skin textures.
* **MobileNet:** Focuses on reducing computational cost, sometimes sacrificing feature extraction power. Lower-level details might be lost, making it harder to detect subtle deepfake manipulations.

**3. Expressive Power and Non-Linearities:**

* **ResNet:** Employs standard convolution layers with non-linear activation functions like ReLU, allowing the model to learn complex relationships between features. This flexibility is beneficial for distinguishing real and fake faces with intricate modifications.
* **MobileNet:** Often uses linear bottleneck layers for efficiency, which can limit the model's ability to learn non-linear relationships. This might hinder its ability to capture the full spectrum of deepfake alterations.

**4. Examples:**

* **Study by Zhao et al. (2020):** Compared ResNet-50 and MobileNetV2 for deepfake detection on the FaceForensics dataset. ResNet-50 achieved an accuracy of 96.4%, while MobileNetV2 reached 92.2%. The deeper architecture and residual connections of ResNet contributed to its superior performance.
* **Another study by Li et al. (2023):** Evaluated various CNN architectures for deepfake detection. ResNet-based models consistently outperformed MobileNet-based models, highlighting the importance of model complexity and feature extraction capabilities.

**Overall, ResNet's deeper architecture, residual connections, and stronger feature extraction abilities make it a more suitable choice for deepfake detection tasks compared to MobileNet, which prioritizes efficiency at the expense of some accuracy.**



"""